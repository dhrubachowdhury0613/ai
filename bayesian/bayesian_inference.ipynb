{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Description\n",
    "\n",
    "<center>![image](images/sleep_data_graph.PNG)</center>\n",
    "\n",
    "My Garmin Vivosmart watch tracks the time I fall asleep and wake up each day using motion sensing and heart rate monitoring. To augment this data, I have estimated likelihoods that I am asleep based on the condition of my bedroom light (on/off) and if my phone is charging (yes/no). My objective is to use this data to create a model that returns the probability I am asleep at a given time. The final goal can be mathematically expressed as:\n",
    "\n",
    "$$P(\\text{sleep} | \\text{time})$$.\n",
    "\n",
    "In probability theory terms, this is the posterior probability I am asleep given the time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wake and Sleep Data Exploration\n",
    "\n",
    "The wake and sleep data contains more than two months of information. The Garmin watch records when I fall asleep and wake up based on motion and heart rate. It is not 100% accurate as it often will think I'm sleeping if I turn off notifications and am quietly reading in bed. Sometimes we have to deal with imperfect data, and, because there are more truthful than false observations, we can expect the correct data to have a larger effect on the model. \n",
    "\n",
    "First, we will import the required libraries, and visualize both the sleep data and the waking data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# scipy for algorithms\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "# pymc3 for Bayesian Inference, pymc built on t\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "\n",
    "# matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "import matplotlib\n",
    "\n",
    "import json\n",
    "s = json.load(open('style/bmh_matplotlibrc.json'))\n",
    "matplotlib.rcParams.update(s)\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 3)\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['ytick.major.size'] = 20\n",
    "\n",
    "# Number of samples for Markov Chain Monte Carlo\n",
    "N_SAMPLES = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data formatted in different notebook\n",
    "sleep_data = pd.read_csv('data/sleep_data.csv')\n",
    "wake_data = pd.read_csv('data/wake_data.csv')\n",
    "\n",
    "# Labels for plotting\n",
    "sleep_labels = ['9:00', '9:30', '10:00', '10:30', '11:00', '11:30', '12:00']\n",
    "wake_labels = ['5:00', '5:30', '6:00', '6:30', '7:00', '7:30', '8:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Falling Asleep Data\n",
    "\n",
    "Each dot represents one observation at a specific time with the color intensity corresponding to the number of points at that time. We can see that I tend to fall asleep a little after 10:00 PM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of sleep observations %d' % len(sleep_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(16, 6)\n",
    "\n",
    "# Sleep data\n",
    "plt.scatter(sleep_data['time_offset'], sleep_data['indicator'], \n",
    "            s= 60, alpha=0.01, facecolor = 'b', edgecolors='b')\n",
    "plt.yticks([0, 1], ['Awake', 'Asleep']); plt.xlabel('PM Time'); \n",
    "plt.title('Falling Asleep Data', size = 18)\n",
    "plt.xticks([-60, -30, 0, 30, 60, 90, 120], sleep_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waking Up Data\n",
    "\n",
    "My alarm is set for 6:00 AM every day of the week, and the wake data is more consistent than the sleep data. I nearly always wake up within a 10 minute window around 6:00 AM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wake data\n",
    "plt.scatter(wake_data['time_offset'], wake_data['indicator'], \n",
    "            s= 50, alpha = 0.01, facecolor='r', edgecolors =  'r');\n",
    "plt.yticks([0, 1], ['Awake', 'Asleep']); plt.xlabel('AM Time');\n",
    "plt.title('Waking Up Data')\n",
    "plt.xticks([-60, -30, 0, 30, 60, 90, 120], wake_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Function to Represent Transition\n",
    "\n",
    "We need to decide on a function to represent the transition from being awake to sleeping. There are a number of acceptable models, and here we will assume this transition can be modeled as a logistic function. A logistic function (also called a sigmoid) is a non-linear function bounded between 0 and 1. As ${t \\to -\\infty}, {p(s|t) \\to 0}$ and, as ${t \\to +\\infty}, {p(s|t) \\to 1}$. The expression for a logistic probability distribution for sleep as a function of time is:\n",
    "\n",
    "$$p(s|t) = \\frac{1}{ 1 + e^{\\;\\beta t } }$$\n",
    "\n",
    "The $\\beta$ parameter is unknown and be esimated using Markov Chain Monte Carlo sampling. MCMC samples from the prior for each parameter, trying to maximize the probabilty of the parameter given the data. \n",
    "\n",
    "Several logistic functions with various $\\beta$ parameters are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(16, 6)\n",
    "\n",
    "# Logistic function with only beta\n",
    "def logistic(x, beta):\n",
    "    return 1. / (1. + np.exp(beta * x))\n",
    "\n",
    "# Plot examples with different betas \n",
    "x = np.linspace(-5, 5, 1000)\n",
    "for beta in [-5, -1, 0.5, 1, 5]:\n",
    "    plt.plot(x, logistic(x, beta), label = r\"$\\beta$ = %.1f\" % beta)\n",
    "\n",
    "plt.legend();\n",
    "plt.title(r'Logistic Function with Different $\\beta$ values');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one problem with the basic logistic function as shown above: the transition is centered at 0. However, in my sleeping data, the transition is around 10:00 pm for sleeping and 6:00 am for waking. We address this by adding an offset, called a bias, to adjust the location of the logistic function. The logistic function now is:\n",
    "\n",
    "$$p(t) = \\frac{1}{ 1 + e^{\\;\\beta t + \\alpha} }$$\n",
    "\n",
    "This introduces another unknown parameter, $\\alpha$, which we will also find from Markov Chain Monte Carlo.\n",
    "\n",
    "The logistic function with various $\\alpha$ and $\\beta$ parameters is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(20, 8)\n",
    "\n",
    "# Logistic function with both beta and alpha\n",
    "def logistic(x, beta, alpha=0):\n",
    "    return 1.0 / (1.0 + np.exp(np.dot(beta, x) + alpha))\n",
    "\n",
    "x = np.linspace(-4, 6, 1000)\n",
    "\n",
    "plt.plot(x, logistic(x, beta=1), label=r\"$\\beta = 1, \\alpha = 0$\", ls=\"--\", lw=2)\n",
    "plt.plot(x, logistic(x, beta=-1), label=r\"$\\beta = -1 \\alpha = 0$\", ls=\"--\", lw=2)\n",
    "\n",
    "plt.plot(x, logistic(x, -1, 1), \n",
    "         label=r\"$\\beta = -1, \\alpha = 1$\", color=\"darkblue\")\n",
    "plt.plot(x, logistic(x, -1, -1),\n",
    "         label=r\"$\\beta = -1, \\alpha = -1$\",color=\"skyblue\")\n",
    "plt.plot(x, logistic(x, -2, 5), \n",
    "         label=r\"$\\beta = -2, \\alpha = 5$\", color=\"orangered\")\n",
    "plt.plot(x, logistic(x, -2, -5), \n",
    "         label=r\"$\\beta = -2, \\alpha = -5$\", color=\"darkred\")\n",
    "plt.legend(); plt.ylabel('Probability'); plt.xlabel('t')\n",
    "plt.title(r'Logistic Function with Varying $\\beta$ and $\\alpha$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\beta$ shifts the direction and steepness of the curve, while $\\alpha$ changes the location. We will use MCMC to find the most likely value of these parameters under the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior Distribution for $\\beta$ and $\\alpha$\n",
    "\n",
    "We have no evidence to suggest what the prior distributions for the model parameters $\\beta$ and $\\alpha$ are ahead of time. Therefore, we can model them as if they came from a normal distribution. The normal, or Gaussian, distribution is defined by the mean, $\\mu$, and the precision, $\\tau$. The precision is the reciprocal of the standard deviation, $\\sigma$. The mean defines the location of the distribution and the precision shows the spread. A larger value of $\\tau$ indicates the data is less spread out (it is more precise) and hence the variation is smaller. The mean can be either positive or negative, but the precision will always be positive. A normal distribution as defined here is represented as:\n",
    "\n",
    "$$ f(x | \\mu, \\tau) = \\sqrt{\\frac{\\tau}{2\\pi}} \\exp\\left( -\\frac{\\tau}{2} (x - \\mu)^2 \\right) $$\n",
    "\n",
    "Probability density functions for three normal distributions are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(20, 8)\n",
    "# Set up the plotting parameters\n",
    "nor = stats.norm \n",
    "x= np.linspace(-10, 10, 1000)\n",
    "mu = (-5, 0, 4)\n",
    "tau = (0.5, 1, 2.5)\n",
    "colors = (\"forestgreen\", \"navy\", \"darkred\")\n",
    "\n",
    "# Plot 3 pdfs for different normal distributions\n",
    "params = zip(mu, tau, colors)\n",
    "for param in params:\n",
    "    y = nor.pdf(x, loc = param[0], scale = 1 / param[1])\n",
    "    plt.plot(x, y, \n",
    "             label=\"$\\mu = %d,\\;\\\\tau = %.1f$\" % (param[0], param[1]), \n",
    "             color = param[2])\n",
    "    plt.fill_between(x, y, color = param[2], alpha = 0.3)\n",
    "    \n",
    "plt.legend(prop={'size':18});\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"Probability Density\", size = 18)\n",
    "plt.title(\"Normal Distributions\", size = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Search Space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scipy.stats as stats\n",
    "from IPython.core.pylabtools import figsize\n",
    "import numpy as np\n",
    "figsize(16, 8)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "jet = plt.cm.jet\n",
    "fig = plt.figure()\n",
    "x = y = np.linspace(0, 5, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "plt.subplot(121)\n",
    "norm_x = stats.norm.pdf(x, loc=0, scale=1)\n",
    "norm_y = stats.norm.pdf(y, loc=0, scale=1)\n",
    "M = np.dot(norm_x[:, None], norm_y[None, :])\n",
    "im = plt.imshow(M, interpolation='none', origin='lower',\n",
    "                cmap=jet)\n",
    "\n",
    "plt.xlim(0, 40)\n",
    "plt.ylim(0, 40)\n",
    "plt.title(\"Parameter Search Space for Normal Priors.\")\n",
    "\n",
    "ax = fig.add_subplot(122, projection='3d')\n",
    "ax.plot_surface(X, Y, M, cmap=plt.cm.jet)\n",
    "ax.view_init(azim=390)\n",
    "plt.title(\"Parameter Search Space for Normal Priors\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected value of a normal distribution is the mean. \n",
    "$$ E[ X | \\mu, \\tau] = \\mu$$ \n",
    "\n",
    "The variance of a normal distribution is equal to:\n",
    "\n",
    "$$ Var[ X | \\mu, \\tau) = \\frac{1}{\\tau}$$\n",
    "\n",
    "Again, we have no assumptions about the value for either $\\mu$ or $\\tau$ in the prior distributions for $\\alpha$ and $\\beta$. When we initialize the model, we can use $\\mu = 0$ and a relatively large variance such as $\\tau = 0.05$. Markov Chain Monte Carlo will samples values of $\\mu$ and $\\tau$ that try to maximize the likelihood of $\\alpha$ and $\\beta$ under the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chain Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov Chain Monte Carlo will sample both $\\beta$ and $\\alpha$ from two normal distributions to find the parameters. Each iteration (state), an estimate for both $\\beta$ and $\\alpha$ are drawn from the prior. If the parameters increase the probabilty of the data, the state is accepted, but if the parameters are not in agreement with the data, the state is rejected. Monte Carlo refers to the sampling part of the algorithm. Markov Chain means that the next state is only dependent on the current state in a first order process (second order depends on the current and 1 previous step, third order on the current and 2 previous steps and so on). MCMC will return every sample of the parameters for the number of specified steps. This is known as the model trace. To find the most likely parameters, we can take the average of the samples in the trace. MCMC does not given an exact answer, but rather tries to find the maximum likelihood states under the data. \n",
    "\n",
    "When modeling with MCMC up to 50% of the initial steps, referred to as the burn-in part of the trace, are discarded because the algorithm returns more likely parameters as the number of samples increases. The initial samples are less likely than the latter samples on average. There are a number of methods to test for convergence of MCMC, including visually inspecting the trace, and calculating the auto-correlation of the trace (a lower auto-correlation is an indicator of convergence). We will look at the trace in this example, but will not take rigorous steps to address convergence. There are also a number of methods to choose a smart starting value for the Markov Chain such as Maximum A Posterior estimation. Choosing an intelligent initial value can speed up convergence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior Probability of Sleep given Time\n",
    "\n",
    "We have all the pieces for the poesterior probabilty and can now put them together. The logistic function describes the transition from awake to asleep, but we do not konw the parameters $\\beta$ and $\\alpha$. The aim is to find the parameters of the logistic function which maximize the likelihood of the observed data. The parameters are assumed to come from a normal distribution defined by a mean, $\\mu$ and a variance, $\\tau$. The MCMC algorithm will sample values of $\\mu$ and $\\tau$ for both $\\alpha$ and $\\beta$ to try and maximize the parameters of the logistic function given the data. \n",
    "\n",
    "The data is connected to the parameters through a Bernoulli Variable.\n",
    "\n",
    "## Bernoulli Variable\n",
    "\n",
    "A bernoulli variable is a discrete random variable that is either 0 or 1. In our example, we can model asleep or awake as a Bernoulli variable where awake is 0 and asleep is 1. The Bernoulli variable for sleep depends on the time, in a manner defined by the logistic function. \n",
    "\n",
    "$$ \\text{Sleep Probability, $S_i$} \\sim \\text{Ber}( \\;p(t_i)\\; ), \\;\\; i=1..N$$\n",
    "\n",
    "$p(t_i)$ is the logistic function with the independent variable time, so this becomes: \n",
    "\n",
    "$$ P(\\text{sleep} | t_i) = \\text{Ber}(\\frac{1}{1 + e^{(\\beta t_i + \\alpha)}})$$\n",
    "\n",
    "The goal of MCMC is to find the $\\alpha$ and $\\beta$ parameters using the data and assuming normal priors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyMC3 Model\n",
    "\n",
    "We are using a powerful Bayesian Inference library in Python called PyMC3. This library has features for running Markov Chain Monte Carlo and other inference algorithms. This report does not detail PyMC3, but a great book for getting started is _Probabilistic Programming and Bayesian Methods for Hackers_ by Cameron Davidson-Pilon which is available for free on [GitHub](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers)\n",
    "\n",
    "The following code creates the model and performs MCMC, drawing `N_SAMPLES` number of samples for $\\beta$ and $\\alpha$. The specific sampling algorithm is [Metropolic Hastings](http://www.mit.edu/~ilkery/papers/MetropolisHastingsSampling.pdf). We feed in the data and tell the model it is observations of the Bernoulli variable. The model then tries to maximize the parameters under the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the values by time offset\n",
    "sleep_data.sort_values('time_offset', inplace=True)\n",
    "\n",
    "# Time is the time offset\n",
    "time = np.array(sleep_data.loc[:, 'time_offset'])\n",
    "\n",
    "# Observations are the indicator\n",
    "sleep_obs = np.array(sleep_data.loc[:, 'indicator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as sleep_model:\n",
    "    # Create the alpha and beta parameters\n",
    "    alpha = pm.Normal('alpha', mu=0.0, tau=0.01, testval=0.0)\n",
    "    beta = pm.Normal('beta', mu=0.0, tau=0.01, testval=0.0)\n",
    "    \n",
    "    # Create the probability from the logistic function\n",
    "    p = pm.Deterministic('p', 1. / (1. + tt.exp(beta * time + alpha)))\n",
    "    \n",
    "    # Create the bernoulli parameter which uses the observed dat\n",
    "    observed = pm.Bernoulli('obs', p, observed=sleep_obs)\n",
    "    \n",
    "    # Starting values are found through Maximum A Posterior estimation\n",
    "    # start = pm.find_MAP()\n",
    "    \n",
    "    # Using Metropolis Hastings Sampling\n",
    "    step = pm.Metropolis()\n",
    "    \n",
    "    # Sample from the posterior using the sampling method\n",
    "    sleep_trace = pm.sample(N_SAMPLES, step=step, njobs=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `trace` variable contains all of the samples drawn from the posterior for $\\beta$ and $\\alpha$. We can graph these samples to explore how they change over the course of sampling. The idea of MCMC is that the samples get more likely given the data as the algorithm continues. In other words, the MCMC algorithm converges on the most likely values as the samples increase. We expect the latter values drawn from the posterior to be more accurate than the earlier values. In Markov Chain Monte Carlo, it is common practice to discard a portion of the samples, usually about 50%, which are known as the burn-in samples. For this report I am not discarding any samples, but in a real application, we would run the model for many more steps and discard the initial samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Posteriors for $\\beta$ and $\\alpha$\n",
    "\n",
    "The values returned in the `trace` are all the samples drawn for the parameters. We can visually inspect these values in histograms.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the alpha and beta samples\n",
    "alpha_samples = sleep_trace[\"alpha\"][5000:, None]\n",
    "beta_samples = sleep_trace[\"beta\"][5000:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(16, 10)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title(r\"\"\"Distribution of $\\alpha$ with %d samples\"\"\" % N_SAMPLES)\n",
    "\n",
    "plt.hist(alpha_samples, histtype='stepfilled', \n",
    "         color = 'darkred', bins=30, alpha=0.8, density=True);\n",
    "plt.ylabel('Probability Density')\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(r\"\"\"Distribution of $\\beta$ with %d samples\"\"\" % N_SAMPLES)\n",
    "plt.hist(beta_samples, histtype='stepfilled', \n",
    "         color = 'darkblue', bins=30, alpha=0.8, density=True)\n",
    "plt.ylabel('Probability Density');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the $\\beta$ values were centered around 0 that would indicate time has no effect on the probability of being asleep. The $\\alpha$ values also are not at 0, indicating that there is an offset from 10:00 pm in terms of being asleep. I choose to represent the times as an offset from 10:00 PM to avoid dealing with data times as much as possible. \n",
    "\n",
    "The spread of the data gives us a measure of uncertainty about the data. A larger spread indicates more uncertainty. As there is considerable overlap in the observations for awake and asleep, the uncertainty is expected to be large. To find the most likely posterior distribution for sleep given the time, we take the average of the $\\alpha$ and $\\beta$ samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior for Sleep Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time values for probability prediction\n",
    "time_est = np.linspace(time.min()- 15, time.max() + 15, 1e3)[:, None]\n",
    "\n",
    "# Take most likely parameters to be mean values\n",
    "alpha_est = alpha_samples.mean()\n",
    "beta_est = beta_samples.mean()\n",
    "\n",
    "# Probability at each time using mean values of alpha and beta\n",
    "sleep_est = logistic(time_est, beta=beta_est, alpha=alpha_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(16, 6)\n",
    "\n",
    "plt.plot(time_est, sleep_est, color = 'navy', \n",
    "         lw=3, label=\"Most Likely Logistic Model\")\n",
    "plt.scatter(time, sleep_obs, edgecolor = 'slateblue',\n",
    "            s=50, alpha=0.2, label='obs')\n",
    "plt.title('Probability Distribution for Sleep with %d Samples' % N_SAMPLES);\n",
    "plt.legend(prop={'size':18})\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('PM Time');\n",
    "plt.xticks([-60, -30, 0, 30, 60, 90, 120], sleep_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior probability increases from 0 to 1 as the time gets later. The model is not perfect because of the noise in the data, but it is an adequate approximation based on the observations and can provide useful estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The probability of sleep increases to above 50% at 10:{} PM.'.format(int(time_est[np.where(sleep_est > 0.5)[0][0]][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#348ABD\", \"#A60628\", \"#7A68A6\"]\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"BMH\", colors)\n",
    "figsize(12, 6)\n",
    "probs = sleep_trace['p']\n",
    "\n",
    "plt.scatter(time, probs.mean(axis=0), cmap = cmap, \n",
    "            c = probs.mean(axis=0), s = 50);\n",
    "plt.title('Probability of Sleep as Function of Time')\n",
    "plt.xlabel('PM Time');\n",
    "plt.ylabel('Probability');\n",
    "plt.xticks([-60, -30, 0, 30, 60, 90, 120], sleep_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior can be queried at any time (as an offset from 10:00 PM) to find the probability I am asleep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('10:00 PM probability of being asleep: {:.2f}%.'.\n",
    "      format(100 * logistic(0, beta_est, alpha_est)))\n",
    "print('9:30  PM probability of being asleep: {:.2f}%.'.\n",
    "      format(100 * logistic(-30, beta_est, alpha_est)))\n",
    "print('10:30 PM probability of being asleep: {:.2f}%.'.\n",
    "      format(100 * logistic(30, beta_est, alpha_est)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other diagnostics of the model that we can perform. For example, we know there is a considerable amount of uncertainty in our estimates for $\\alpha$ and $\\beta$. To reflect this in the graph, we can include include the 95% confidence interval at each time based on all of the samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_all_est = logistic(time_est.T, beta_samples, alpha_samples)\n",
    "quantiles = stats.mstats.mquantiles(sleep_all_est, [0.025, 0.975], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(time_est[:, 0], *quantiles, alpha=0.6, \n",
    "                 color='slateblue', label = '95% CI')\n",
    "plt.plot(time_est, sleep_est, lw=2, ls='--', \n",
    "         color='black', label=\"average posterior \\nprobability of sleep\")\n",
    "plt.xticks([-60, -30, 0, 30, 60, 90, 120], sleep_labels);\n",
    "plt.scatter(time, sleep_obs, edgecolor = 'skyblue', s=50, alpha=0.1);\n",
    "plt.legend(prop={'size':14})\n",
    "plt.xlabel('PM Time'); plt.ylabel('Probability'); \n",
    "plt.title('Posterior Probabilty with 95% CI');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each time, there is a measure of uncertainty as to whether or not I am asleep. This represents the fact that MCMC does not return the True parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Probability Distribution for Specific Time\n",
    "\n",
    "We can also plot the posterior distribution of sleep at a time as a histogram based on all of the samples for the paramters. This gives us another look at the uncertainty in the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_posterior(time_offset, time):\n",
    "    figsize(16, 8)\n",
    "    prob = logistic(time_offset, beta_samples, alpha_samples)\n",
    "    plt.hist(prob, bins=100, histtype='step', lw=4)\n",
    "    plt.title('Probability Distribution for Sleep at %s PM' % time)\n",
    "    plt.xlabel('Probability of Sleep'); plt.ylabel('Samples')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_posterior(0, '10:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_posterior(-30, '9:30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_posterior(30, '10:30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence in Markov Chain Monte Carlo\n",
    "\n",
    "How can we know if the model converged? We can look at the trace, or the path of the values over sampling. Another option is to look at the auto-correlation of the samples. In Markov Chain modeling, the samples are correlated with themselves because the next value depends on the current state (or the current state and past states based on the order). Initially, the algorithm tends to wander about the search space and will have a high auto-correlation. As the algorithm converges, the samples will settle down around a value and one measure of convergence is a low auto-correlation. We will not do a rigorous study of convergence in this report, but we can plot the traces of all the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace Plots\n",
    "\n",
    "The plots below show all the samples of $\\alpha$ and $\\beta$ from the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(12, 6)\n",
    "\n",
    "# Plot alpha trace\n",
    "plt.subplot(211)\n",
    "plt.title(r'Trace of $\\alpha$')\n",
    "plt.plot(alpha_samples, color = 'darkred')\n",
    "plt.xlabel('Samples'); plt.ylabel('Parameter');\n",
    "\n",
    "# Plot beta trace\n",
    "plt.subplot(212)\n",
    "plt.title(r'Trace of $\\beta$')\n",
    "plt.plot(beta_samples, color='b')\n",
    "plt.xlabel('Samples'); plt.ylabel('Parameter');\n",
    "plt.tight_layout(h_pad=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built in Diagnostics\n",
    "\n",
    "PyMC3 has many built-in diagnostics for model evaluation. Here are the trace plot and autocorrelation plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(20, 12)\n",
    "pm.traceplot(sleep_trace, ['alpha', 'beta']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.autocorrplot(sleep_trace, ['alpha', 'beta']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wake Model\n",
    "\n",
    "We can repeat the same procedure to find a model for the wake data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the values by time offset\n",
    "wake_data.sort_values('time_offset', inplace=True)\n",
    "\n",
    "# Time is the time offset\n",
    "time = np.array(wake_data.loc[:, 'time_offset'])\n",
    "\n",
    "# Observations are the indicator\n",
    "wake_obs = np.array(wake_data.loc[:, 'indicator'])\n",
    "\n",
    "with pm.Model() as wake_model:\n",
    "    # Create the alpha and beta parameters\n",
    "    alpha = pm.Normal('alpha', mu=0.0, tau=0.01, testval=0.0)\n",
    "    beta = pm.Normal('beta', mu=0.0, tau=0.01, testval=0.0)\n",
    "    \n",
    "    # Create the probability from the logistic function\n",
    "    p = pm.Deterministic('p', 1. / (1. + tt.exp(beta * time + alpha)))\n",
    "    \n",
    "    # Create the bernoulli parameter which uses the observed data\n",
    "    observed = pm.Bernoulli('obs', p, observed=wake_obs)\n",
    "    \n",
    "    # Starting values are found through Maximum A Posterior estimation\n",
    "    # start = pm.find_MAP()\n",
    "    \n",
    "    # Using Metropolis Hastings Sampling\n",
    "    step = pm.Metropolis()\n",
    "    \n",
    "    # Sample from the posterior using the sampling method\n",
    "    wake_trace = pm.sample(N_SAMPLES, step=step, njobs=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Posterior for Wake given Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the alpha and beta samples\n",
    "alpha_samples = wake_trace[\"alpha\"][5000:, None]\n",
    "beta_samples = wake_trace[\"beta\"][5000:, None]\n",
    "\n",
    "# Time values for probability prediction\n",
    "time_est = np.linspace(time.min()- 15, time.max() + 15, 1e3)[:, None]\n",
    "\n",
    "# Take most likely parameters to be mean values\n",
    "alpha_est = alpha_samples.mean()\n",
    "beta_est = beta_samples.mean()\n",
    "\n",
    "# Probability at each time using mean values of alpha and beta\n",
    "wake_est = logistic(time_est, beta=beta_est, alpha=alpha_est)\n",
    "\n",
    "figsize(12, 5)\n",
    "\n",
    "plt.plot(time_est, wake_est, color = 'darkred', \n",
    "         lw=3, label=\"average posterior \\nprobability of wake\")\n",
    "plt.scatter(time, wake_obs, edgecolor = 'r', facecolor = 'r', \n",
    "            s=50, alpha=0.05, label='obs')\n",
    "plt.title('Posterior Probability of Wake with %d Samples' % N_SAMPLES);\n",
    "plt.legend(prop={'size':14})\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('AM Time');\n",
    "plt.xticks([-60, -30, 0, 30, 60, 90, 120], wake_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does not have a steep transition, which is what I expected because I tend to wake up right around 6:00 AM. There were several times when I woke up several hours later which shifted the curve to the right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The probability of being awake passes 50% at 6:{} AM.'.format(int(time_est[np.where(wake_est < 0.5)][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#348ABD\", \"#A60628\", \"#7A68A6\"]\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"BMH\", colors)\n",
    "figsize(12, 6)\n",
    "probs = wake_trace['p']\n",
    "\n",
    "plt.scatter(time, probs.mean(axis=0), cmap = cmap, \n",
    "            c = probs.mean(axis=0), s = 50);\n",
    "plt.title('Probability of Sleep as Function of Time')\n",
    "plt.xlabel('AM Time');\n",
    "plt.ylabel('Probability');\n",
    "plt.xticks([-60, -30, 0, 30, 60, 90, 120], wake_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the Wake Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Probability of being awake at 5:30 AM: {:.2f}%.'.\n",
    "      format(100 - (100 * logistic(-30, beta=beta_est, alpha=alpha_est))))\n",
    "print('Probability of being awake at 6:00 AM: {:.2f}%.'.\n",
    "      format(100 - (100 * logistic(0, beta=beta_est, alpha=alpha_est))))\n",
    "print('Probability of being awake at 6:30 AM: {:.2f}%.'.\n",
    "      format(100 - (100 * logistic(30, beta=beta_est, alpha=alpha_est))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Interval \n",
    "\n",
    "To represent the uncertainty, we can calculate the 95% confidence interval for the probability of being asleep at each time. MCMC does not return the True distribution, but an approximation that we hope represents the observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wake_all_est = logistic(time_est.T, beta_samples, alpha_samples)\n",
    "quantiles = mquantiles(wake_all_est, [0.025, 0.975], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(time_est[:, 0], *quantiles, \n",
    "                 alpha=0.6, color='salmon', label = '95% CI')\n",
    "plt.plot(time_est, wake_est, lw=2, ls='--', \n",
    "         color='black', label=\"average posterior \\nprobability of sleep\")\n",
    "plt.xticks([-60, -30, 0, 30, 60, 90, 120], wake_labels);\n",
    "plt.scatter(time, sleep_obs, edgecolor = 'red', \n",
    "            facecolor = 'red', s=50, alpha=0.1);\n",
    "plt.legend(prop={'size':14})\n",
    "plt.xlabel('AM Time'); plt.ylabel('Probability'); \n",
    "plt.title('Posterior Probabilty with 95% CI');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for Sleep Duration\n",
    "\n",
    "We can also form a model to estimate the most likely length of time I am asleep. We can first look at the data and then determine which function fits the probability distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('data/sleep_wake.csv')\n",
    "raw_data['length'] = 8 - (raw_data['Sleep'] / 60) + (raw_data['Wake'] / 60)\n",
    "duration = raw_data['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(10, 8)\n",
    "plt.hist(duration, bins = 20, color = 'darkred')\n",
    "plt.xlabel('Hours'); plt.title('Length of Sleep Distribution'); \n",
    "plt.ylabel('Observations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is skewed to the right. Therefore, we can used a skewed distribution to model the length of sleep. We might also want to use a bi-modal distribution because there appear to be two modes. For now, I will stick to representing the length of sleep distribution as a skewed normal. A skewed normal distribution is shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 3\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "x = np.linspace(6, 12, 1e3)\n",
    "\n",
    "\n",
    "figsize(10, 8)\n",
    "plt.hist(duration, bins = 20, color = 'darkred', normed=True)\n",
    "plt.xlabel('Hours'); plt.title('Length of Sleep Distribution with Skewed PDF'); \n",
    "plt.ylabel('Observations');\n",
    "plt.plot(x, stats.skewnorm.pdf(x, a, loc = 7.4, scale=1), 'r-', \n",
    "         lw=3, label='skewnorm pdf');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as duration_model:\n",
    "    # Three parameters to sample\n",
    "    alpha_skew = pm.Normal('alpha_skew', mu=0, tau=0.5, testval=3.0)\n",
    "    mu_ = pm.Normal('mu', mu=0, tau=0.5, testval=7.4)\n",
    "    tau_ = pm.Normal('tau', mu=0, tau=0.5, testval=1.0)\n",
    "    \n",
    "    # Duration is a deterministic variable\n",
    "    duration_ = pm.SkewNormal('duration', alpha = alpha_skew, mu = mu_, \n",
    "                              sd = 1/tau_, observed = duration)\n",
    "    \n",
    "    # Metropolis Hastings for sampling\n",
    "    step = pm.Metropolis()\n",
    "    duration_trace = pm.sample(N_SAMPLES, step=step)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the most likely estimates from the sampling\n",
    "alpha_skew_samples = duration_trace['alpha_skew'][5000:]\n",
    "mu_samples = duration_trace['mu'][5000:]\n",
    "tau_samples = duration_trace['tau'][5000:]\n",
    "\n",
    "alpha_skew_est = alpha_skew_samples.mean()\n",
    "mu_est = mu_samples.mean()\n",
    "tau_est = tau_samples.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Posterior Distribution for Sleep Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(6, 12, 1000)\n",
    "y = stats.skewnorm.pdf(x, a = alpha_skew_est, loc=mu_est, scale=1/tau_est)\n",
    "plt.plot(x, y, color = 'forestgreen')\n",
    "plt.fill_between(x, y, color = 'forestgreen', alpha = 0.2);\n",
    "plt.xlabel('Hours'); plt.ylabel('Probability'); \n",
    "plt.title('Posterior Distribution for Duration of Sleep');\n",
    "plt.vlines(x = x[np.argmax(y)], ymin=0, ymax=y.max(), \n",
    "           linestyles='--', linewidth=2, color='red', \n",
    "           label = 'Most Likely Duration');\n",
    "\n",
    "print('The most likely duration of sleep is {:.2f} hours.'.format(x[np.argmax(y)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the Posterior Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Probability of at least 6.5 hours of sleep = {:.2f}%.'.\n",
    "      format(100 * (1 - stats.skewnorm.cdf(6.5, a = alpha_skew_est, loc = mu_est, scale = 1/tau_est))))\n",
    "print('Probability of at least 8.0 hours of sleep = {:.2f}%.'.\n",
    "      format(100 * (1 - stats.skewnorm.cdf(8.0, a = alpha_skew_est, loc = mu_est, scale = 1/tau_est))))\n",
    "print('Probability of at least 9.0 hours of sleep = {:.2f}%.'.\n",
    "      format(100 * (1 - stats.skewnorm.cdf(9.0, a = alpha_skew_est, loc = mu_est, scale = 1/tau_est))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Posterior and the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(6, 12, 1000)\n",
    "y = stats.skewnorm.pdf(x, a = alpha_skew_est, loc=mu_est, scale=1/tau_est)\n",
    "\n",
    "# Plot the posterior distribution\n",
    "plt.plot(x, y, color = 'forestgreen', \n",
    "         label = 'Posterior Distribution', lw = 3)\n",
    "plt.fill_between(x, y, color = 'forestgreen', alpha = 0.2);\n",
    "\n",
    "# Plot the observed values\n",
    "plt.hist(duration, bins=10, color = 'red', alpha=0.8,\n",
    "         label='Observed', normed=True)\n",
    "plt.xlabel('Hours'); plt.ylabel('Probability'); \n",
    "plt.title('Observations and Posterior Distribution');\n",
    "plt.vlines(x = x[np.argmax(y)], ymin=0, ymax=y.max(), \n",
    "           linestyles='--', linewidth=2, color='k', \n",
    "           label = 'Most Likely Duration');\n",
    "plt.legend(prop={'size':12});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior skewed normal distribution looks to fit the data well. However, the data may be better modeled as two separate distributions given the second mode to the right. The second mode is not captured in a single skewed normal distribution. Overall, this model still provides a reasonable estimate for the probabilty of duration of my sleep. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "Based on the observations, we can state the following: \n",
    "\n",
    "* __On average I fall asleep by 10:14 PM__\n",
    "* __On average I wake up by 6:11 AM__\n",
    "* __My average duration of sleep is 7.66 hours__\n",
    "    \n",
    "The models have already provided me with knowledge about my sleeping patterns, and more data would only improve the applicability. I could incorporate additional information such as day of the week or daily activities to see how they affect my sleep and then make adjustments as required. Although this report made several assumptions and did not fully investigate the models, it was a great start towards analyzing actual data with Bayesian methods. Projects, especially with real applications, are the best way to learn, and I look forward to applying Bayesian methods to additional problems! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
